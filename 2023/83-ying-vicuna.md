# Ying Sheng:  From Vicuna to human-aligned evaluation

## Upcoming Events
Join our Meetup group for more events!
https://www.meetup.com/data-umbrella

## Key Links
- Transcript: https://github.com/data-umbrella/event-transcripts/blob/main/2023/83-ying-vicuna.md
- Meetup Event: https://www.meetup.com/data-umbrella/events/294139850/
- Video: 
- GitHub repo:  
- Transcriber:  ? [needs a transcriber]

## Resources
- FastChat on GitHub: https://github.com/lm-sys/FastChat
- Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality: https://lmsys.org/blog/2023-03-30-vicuna/
- Large Models Systems Organization on GitHub: https://github.com/lm-sys

## About the Event
We will talk about the training and deployment experiences of Vicuna, which is a high-quality chat assistant. After training the models, we found evaluating them even more difficult, so we launched Chatbot Arena, a crowd-sourced benchmarking platform featuring randomized battles. However, relying on human evaluation is costly and slow, so we study whether we can replace human evaluators with strong LLMs like GPT-4 for evaluating these models. We termed this approach “LLM-as-a-judge”.


```
## Timestamps
00:00 Help us add timestamps
```
https://github.com/data-umbrella/event-transcripts/issues/92

## About the Speaker
Ying Sheng

- Twitter: https://twitter.com/ying11231  
- GitHub:  https://github.com/Ying1123

## Video:  ** NEED TO UPDATE **
<a href="http://www.youtube.com/watch?feature=player_embedded&v=NbmdFJsnuuo" target="_blank"><img src="http://img.youtube.com/vi/NbmdFJsnuuo/0.jpg"
alt="From Vicuna to human-aligned evaluation" width="50%" /></a>

## Timestamps
[get from video]

## Transcript
